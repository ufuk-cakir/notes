---
title: 📝 Rectified Linear Unit (ReLU)
tags:
  - ML
---
is an [[Activation Function]]

$$f(x)= \begin{cases}x & \text { if } x>0 \\ 0 & \text { otherwise }\end{cases}$$