{"/":{"title":"ðŸª´ Notes","content":"\n\n# Notes \nTest\n\n\n","lastmodified":"2023-05-14T20:14:57.504600218Z","tags":[]},"/Backpropagation":{"title":"Backpropagation","content":"\n\n# Training Neural Networks by Backpropagation\n\nBackpropagation is simply a fancier name for the chain rule of calculus.\n\n\nWe want to train $B_1,\\dots,B_L$  (The Matrix of weight vectors, which are column vectors) by gradient decent, so we need the derivative of\n\n$$\\frac{\\partial \\operatorname{loss}}{\\partial B_l}$$\nand then update by\n$$B_l^{(t)}=B_l^{(t-1)}-\\tau \\cdot \\frac{\\partial\\text{loss}}{\\partial B_l^{(t-1)}}$$\n\n1. Step:  Calculate derivative of the loss w.r.t Network output: $$\\frac{\\partial \\operatorname{loss}}{\\partial z_l}$$ The loss is application dependent: For example for **regression** we have  $$\\text{loss}=\\frac{1}{2}\\left(z_L-y_i^*\\right)^2\\qquad\\frac{\\partial \\operatorname{loss}}{\\partial z_L}=z_L-y_i^*$$ Or for classication we have the **cross entropy loss**:  $$\\text{loss}=-\\sum_{k=1}^c \\mathbb{1}\\left[ k=y_i^{*}\\right]\\log \\frac{p(Y=k \\mid X)}{z_{Lk}}$$$$\\frac{\\partial \\operatorname{loss}}{\\partial z_{L k}}=\\left\\{\\begin{array}{c}-\\frac{1}{z_{Lk}} \\qquad\\text{if } k=y_i^* \\\\ 0  \\qquad \\text { othermise }\\end{array}\\right.$$\n2.  Step: Backpropagate through output activation $\\varphi_L(\\tilde z_L$). First define $$\\tilde{\\delta}_L=\\frac{\\partial L}{\\partial \\tilde z_L}$$\n","lastmodified":"2023-05-14T20:14:57.504600218Z","tags":[]},"/Summary-Linear-Classification":{"title":"Summary Linear Classification","content":"# Summary of Linear Classification\nwith $y \\in\\{-1,1\\}$ : All methods have the same decision Rule\n\n$$\n\\hat{y}_i=\\operatorname{sign}\\left(x_i \\cdot \\beta+b\\right)\n$$\n\nBut: Methods differ by how they define and find the optimal $\\beta$ and $b$ \nthe common objective function is to have \n\n$$\n\\hat{\\beta}, \\hat{b}=\\arg \\min _{\\beta, b} \\frac{\\lambda}{2} \\beta^T \\beta+\\frac{1}{N} \\sum_{i=1}^N \\operatorname{loss}\\left(y_i^*, x_i, \\beta+b\\right)\n$$\nWhere the first term is the **Regularization** Term, and the second is called the **Data Term**\n- Data Term: takes care that we solve the right problem\n- Regularization prevents overfitting\n\nThe Methods differ by regularization and loss\n\nWe had 4 Methods:\n- Perceptron:\n\t- Loss: $\\operatorname{ReLu}\\left(\\left(-y_i^*\\left(x_i \\beta+b\\right)\\right)\\right.$\n\t- regularization: $\\lambda =0$\n- SVM:\n\t- Loss: $\\operatorname{ReLu}\\left(\\left(1-y_i^*\\left(x_i \\beta+b\\right)\\right)\\right.$\n\t-  regularization: $\\lambda \u003e0$\n \n- LDA\n\t- Loss: $\\left(y_i^{*}-\\left(x_i \\beta+b\\right)\\right)^2$\n\t-  regularization: $\\lambda =0$ if we fit $\\mu,\\sigma$ and $\\lambda\u003e0$ if we fit via objective\n- Logistic Regression (LR)\n\t- $\\operatorname{softplus}\\left(-y_i^*\\left(x_i \\beta+(s)\\right)\\right)$\n\t- regularizaizon: either $\\lambda = 0$ or $\\lambda\u003e0$\n\t\t- if you find that the LR overfits you can add the regularizazion term\n\n\nIn practice:\nSimilar solutions when data are nearly linearly seperable and different tradeoffs otherwise. So you have to check with a validation test. IMPORTANT: you should NOT check with the test set, because selecting an algorithm is part of training, and if you use the test data for selecting an algortithm it would become part of the training data and you have no test data anymore","lastmodified":"2023-05-14T20:14:57.504600218Z","tags":[]},"/notes/config":{"title":"Configuration","content":"\n## Configuration\nQuartz is designed to be extremely configurable. You can find the bulk of the configuration scattered throughout the repository depending on how in-depth you'd like to get.\n\nThe majority of configuration can be found under `data/config.yaml`. An annotated example configuration is shown below.\n\n```yaml {title=\"data/config.yaml\"}\n# The name to display in the footer\nname: Jacky Zhao\n\n# whether to globally show the table of contents on each page\n# this can be turned off on a per-page basis by adding this to the\n# front-matter of that note\nenableToc: true\n\n# whether to by-default open or close the table of contents on each page\nopenToc: false\n\n# whether to display on-hover link preview cards\nenableLinkPreview: true\n\n# whether to render titles for code blocks\nenableCodeBlockTitle: true \n\n# whether to render copy buttons for code blocks\nenableCodeBlockCopy: true \n\n# whether to render callouts\nenableCallouts: true\n\n# whether to try to process Latex\nenableLatex: true\n\n# whether to enable single-page-app style rendering\n# this prevents flashes of unstyled content and improves\n# smoothness of Quartz. More info in issue #109 on GitHub\nenableSPA: true\n\n# whether to render a footer\nenableFooter: true\n\n# whether backlinks of pages should show the context in which\n# they were mentioned\nenableContextualBacklinks: true\n\n# whether to show a section of recent notes on the home page\nenableRecentNotes: false\n\n# whether to display an 'edit' button next to the last edited field\n# that links to github\nenableGitHubEdit: true\nGitHubLink: https://github.com/jackyzha0/quartz/tree/hugo/content\n\n# whether to render mermaid diagrams\nenableMermaid: true\n\n# whether to use Operand to power semantic search\n# IMPORTANT: replace this API key with your own if you plan on using\n# Operand search!\nsearch:\n  enableSemanticSearch: false\n  operandApiKey: \"REPLACE-WITH-YOUR-OPERAND-API-KEY\"\n  operandIndexId: \"REPLACE-WITH-YOUR-OPERAND-INDEX-ID\"\n\n# page description used for SEO\ndescription:\n  Host your second brain and digital garden for free. Quartz features extremely fast full-text search,\n  Wikilink support, backlinks, local graph, tags, and link previews.\n\n# title of the home page (also for SEO)\npage_title:\n  \"ðŸª´ Quartz 3.3\"\n\n# links to show in the footer\nlinks:\n  - link_name: Twitter\n    link: https://twitter.com/_jzhao\n  - link_name: Github\n    link: https://github.com/jackyzha0\n```\n\n### Code Block Titles\nTo add code block titles with Quartz:\n\n1. Ensure that code block titles are enabled in Quartz's configuration:\n\n    ```yaml {title=\"data/config.yaml\", linenos=false}\n    enableCodeBlockTitle: true\n    ```\n\n2. Add the `title` attribute to the desired [code block\n   fence](https://gohugo.io/content-management/syntax-highlighting/#highlighting-in-code-fences):\n\n      ```markdown {linenos=false}\n       ```yaml {title=\"data/config.yaml\"}\n       enableCodeBlockTitle: true  # example from step 1\n       ```\n      ```\n\n**Note** that if `{title=\u003cmy-title\u003e}` is included, and code block titles are not\nenabled, no errors will occur, and the title attribute will be ignored.\n\n### HTML Favicons\nIf you would like to customize the favicons of your Quartz-based website, you \ncan add them to the `data/config.yaml` file. The **default** without any set \n`favicon` key is:\n\n```html {title=\"layouts/partials/head.html\", linenostart=15}\n\u003clink rel=\"shortcut icon\" href=\"icon.png\" type=\"image/png\"\u003e\n```\n\nThe default can be overridden by defining a value to the `favicon` key in your \n`data/config.yaml` file. For example, here is a `List[Dictionary]` example format, which is\nequivalent to the default:\n\n```yaml {title=\"data/config.yaml\", linenos=false}\nfavicon:\n  - { rel: \"shortcut icon\", href: \"icon.png\", type: \"image/png\" }\n#  - { ... } # Repeat for each additional favicon you want to add\n```\n\nIn this format, the keys are identical to their HTML representations.\n\nIf you plan to add multiple favicons generated by a website (see list below), it\nmay be easier to define it as HTML. Here is an example which appends the \n**Apple touch icon** to Quartz's default favicon:\n\n```yaml {title=\"data/config.yaml\", linenos=false}\nfavicon: |\n  \u003clink rel=\"shortcut icon\" href=\"icon.png\" type=\"image/png\"\u003e\n  \u003clink rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"/apple-touch-icon.png\"\u003e\n```\n\nThis second favicon will now be used as a web page icon when someone adds your \nwebpage to the home screen of their Apple device. If you are interested in more \ninformation about the current and past standards of favicons, you can read \n[this article](https://www.emergeinteractive.com/insights/detail/the-essentials-of-favicons/).\n\n**Note** that all generated favicon paths, defined by the `href` \nattribute, are relative to the `static/` directory.\n\n### Graph View\nTo customize the Interactive Graph view, you can poke around `data/graphConfig.yaml`.\n\n```yaml {title=\"data/graphConfig.yaml\"}\n# if true, a Global Graph will be shown on home page with full width, no backlink.\n# A different set of Local Graphs will be shown on sub pages.\n# if false, Local Graph will be default on every page as usual\nenableGlobalGraph: false\n\n### Local Graph ###\nlocalGraph:\n    # whether automatically generate a legend\n    enableLegend: false\n    \n    # whether to allow dragging nodes in the graph\n    enableDrag: true\n    \n    # whether to allow zooming and panning the graph\n    enableZoom: true\n    \n    # how many neighbours of the current node to show (-1 is all nodes)\n    depth: 1\n    \n    # initial zoom factor of the graph\n    scale: 1.2\n    \n    # how strongly nodes should repel each other\n    repelForce: 2\n\n    # how strongly should nodes be attracted to the center of gravity\n    centerForce: 1\n\n    # what the default link length should be\n    linkDistance: 1\n    \n    # how big the node labels should be\n    fontSize: 0.6\n    \n    # scale at which to start fading the labes on nodes\n    opacityScale: 3\n\n### Global Graph ###\nglobalGraph:\n\t# same settings as above\n\n### For all graphs ###\n# colour specific nodes path off of their path\npaths:\n  - /moc: \"#4388cc\"\n```\n\n\n## Styling\nWant to go even more in-depth? You can add custom CSS styling and change existing colours through editing `assets/styles/custom.scss`. If you'd like to target specific parts of the site, you can add ids and classes to the HTML partials in `/layouts/partials`. \n\n### Partials\nPartials are what dictate what gets rendered to the page. Want to change how pages are styled and structured? You can edit the appropriate layout in `/layouts`.\n\nFor example, the structure of the home page can be edited through `/layouts/index.html`. To customize the footer, you can edit `/layouts/partials/footer.html`\n\nMore info about partials on [Hugo's website.](https://gohugo.io/templates/partials/)\n\nStill having problems? Checkout our [FAQ and Troubleshooting guide](notes/troubleshooting.md).\n\n## Language Support\n[CJK + Latex Support (æµ‹è¯•)](notes/CJK%20+%20Latex%20Support%20(æµ‹è¯•).md) comes out of the box with Quartz.\n\nWant to support languages that read from right-to-left (like Arabic)? Hugo (and by proxy, Quartz) supports this natively.\n\nFollow the steps [Hugo provides here](https://gohugo.io/content-management/multilingual/#configure-languages) and modify your `config.toml`\n\nFor example:\n\n```toml\ndefaultContentLanguage = 'ar'\n[languages]\n  [languages.ar]\n    languagedirection = 'rtl'\n    title = 'Ù…Ø¯ÙˆÙ†ØªÙŠ'\n    weight = 1\n```\n","lastmodified":"2023-05-14T20:14:57.504600218Z","tags":["setup"]},"/notes/machine-learning/Alternatives-for-learnine-beta-and-b":{"title":"Alternatives for learnine beta and b","content":"\n## Alternatives for learning $\\beta$ and b\n1. fit mean and covariance of clusters\n2. least- squares regression: $$\n\\operatorname{loss}\\left(Y_i^*, \\hat{Y}_i\\right)=\\left(Y_i^*-(x \\beta+b)\\right)^2\n$$\n3. Fishers original idea: define 1D scores: \n4. $$z_{i}= x_{i}\\beta$$\n5. and choose beta such that a threshold classifier on z_i has minimum error\ndefine Projection of means \n$$\n\\tilde{\\mu}_1=\\mu_{1} \\beta \\quad \\tilde{\\mu}_{-1}=\\mu_{-1} \\beta\n$$\n\nThe intuition tells us that $\\tilde{\\mu}_1$ and $\\tilde{\\mu}_{-1}$ should be as far apart as possible, so one could suggest that$$\n\\beta=\\arg \\max _\\mu\\left(\\tilde{\\mu}_1-\\tilde{\\mu}_{-1}\\right)^2\n$$\nBut this doesnt work!\nSince we could scale $\\beta$ by any number $\\tau$ and get the same projection, but make the difference as big as we want.\n\nSolution: Scale by the variance!\n\n$$\n\\sigma_1^2=\\operatorname{Var}\\left(z_i \\mid Y_i^*=1\\right) \\quad \\sigma_{-1}^2=\\operatorname{Var}\\left(z_i \\mid Y_i^*=-1\\right)\n$$\n\nAnd then choose\n$$\n\\hat{\\beta}=\\operatorname{argmax}_p \\frac{\\left(\\tilde{\\mu}_1-\\tilde{\\mu}_{-1}\\right)^2}{\\tilde\\sigma_1^2+\\tilde{\\sigma}_{-1}^2}\n$$\nWhich gives the same solution as 1. and 2.\n\n\nBut is there a way we get a different solution?\n\nYES!\n\n![[Logisitic Regression]]","lastmodified":"2023-05-14T20:14:57.504600218Z","tags":[]},"/notes/machine-learning/Covariance-Matrix":{"title":"Covariance Matrix","content":"","lastmodified":"2023-05-14T20:14:57.504600218Z","tags":[]},"/notes/machine-learning/Cross-Validation":{"title":"Cross Validation","content":"\n\nHow to find good parameter?\nThe Support Vector Machine has a hyper parameter: relative Weight of the data and regularization term.\n\n- regularization Term: tries to maximize the margin in order to prevent overfitting\n- data term: responsible for classifying the data term correctly\n\nQuestin: how do you find a good hyperparameter?\n\nThe standard approaches to hyperparameter selection:\n\nThe best is if you have 3 Datasets: Training, validation, test.\n\nThe idea is: \n- You pick a set of possible hyperparameters .ie $\\beta  \\in {10^{-3}, 10^{-1},1,10,100}$\n- train with each $\\beta$ on the training set \n-  measure the accuracy on the validation set\n- keep best $\\beta$ on validatoin set\n- test again on test set\n\nWhy not get rid of validation test? If we select the hyperparamter on the test set, the test set secretly becomes part of the training set and hence is no test set anymore. This is why we need a second test set that is part of the training in order to preserve the test set for real testing.\n\n## Fallback withoud validation set: cross-validation\nidea: split the training set into k pieces (\"folds\")\n\nIt is really importatn that the Test set is randomly ordered.\n\n- split up the test set into e.g 5 folds\n- use each fold as validation set in term and train on the remaining k-1 folds\n- in the second iteration use second set and train on the remaining folds etc\n- Typical values for K: 2(only used if you cant afford more than 2 times), better is 5 or 10 Folds, (N-fold: \"leave-one-out cross validation\": leave one point out and train on all the data except that one). Often one can calculate the leave one out error analytically which is very nice!\n- can also be applied hierarchically:\n\t- first take one fold out as a test set\n\t- take another one out as a validation set\n\t- train on the remaining folds\n\t- in the inner loop you would flip around the validation sets and in the outer loop you would flip around the test set\n- K-Error Estimates after we trained: Report average error and variance: The best hyperparameter is the one with the lowest average error","lastmodified":"2023-05-14T20:14:57.504600218Z","tags":[]},"/notes/machine-learning/Gaussian-Distribution-in-1-D":{"title":"Gaussian Distribution in 1-D","content":"\n$$N\\left(x \\mid \\mu, \\sigma^2\\right)=\\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp \\left(-\\frac{1}{2}\\left(\\frac{(x-\\mu)^2}{\\sigma^2}\\right)\\right.$$\n\n\nStandard Normal Distribution: $\\mu = 0, \\sigma^2 = 1$\n\n","lastmodified":"2023-05-14T20:14:57.504600218Z","tags":[]},"/notes/machine-learning/Linear-Discriminant-Analysis":{"title":"Linear Discriminant Analysis","content":"\n\nIdea:\n- We have two classes and we assume that the features of each class form a cluster\n- then we model each cluster as a gaussian distribution, which means we have a generative model i.e the RHS of Bayes\n- Calculate the Posterior from the bayes formula\n\nVariant 1: Quadratic Discriminant Analysis (QDA)\n- both clusters can have different shapes\n\nVariant 2: LDA\n- both clusters have the same shape\n- -\u003e LHS of Bayes reduces to a linear decision rule i.e $\\hat y = sign(x\\\\beta + b)$ \n- all the nonlinear terms cancel out\n\nFirst of all: How do get to a gaussian?\n\nClusters are assumed to be elliptic (circles are unrealistic).\n\n- Start from unit circle\n- Step 1: axis aligned scaling. Scale the unit circle with $\\lambda=\\left(\\begin{array}{ll}r_1 \u0026 0 \\\\ 0 \u0026 r_2\\end{array}\\right)$\n- Step 2: Rotation around origin\n- Step 3: Translate to the mean\n\n\n$$z = \\lambda^{-1} Q^{-1}(x-\\mu)$$\n$$z = \\lambda^{-1} Q^T(x-\\mu)$$\n ![[Gaussian Distribution in 1-D]]\n\nClusters are unit circles around the origin:\n$$N\\left(z \\mid \\mu=0, \\Sigma=1\\right)=\\frac{1}{\\sqrt{(2 \\pi)^d}} \\exp \\left(-\\frac{1}{2} z z^{\\top}\\right)$$\nwhere d is the dimension\n\n![[Multi variate Gaussian]]\n\n\nWe can write \n$$\\Sigma = Q\\lambda^2Q^T$$\nwhich is the Eigendecomposition of $\\Sigma$, with the eigenvalues $\\lambda$ and the Eigenvectors $Q$ \n\n\n---\nNow lets fit a gaussian to a cluster. We with only one cluster\n\n$$N\\left(x_i \\mid \\mu_1, \\Sigma_1\\right)=\\frac{\\exp \\left(-\\frac{1}{2}(\\mathbf{x_i}-\\boldsymbol{\\mu_1})^{\\mathrm{T}} \\boldsymbol{\\Sigma_1}^{-1}(\\mathbf{x_i}-\\boldsymbol{\\mu_1})\\right)}{\\sqrt{\\det{2\\pi\\Sigma_1}}}$$\n\nLearning Problem: Find the mean and covariance of class 1 $\\mu_1,\\Sigma_1$\n\nFundamental Principle: Choose $\\mu_1,\\Sigma_1$ such that the Training set will be a typical outcome of the resulting model. You want to choose the model such that If you draw data from the model it should look very similar to the trainin set. This is called the \n**Maximum Likelihood Principle**: The best model maximises the likelihood of the Trainin set\n\n- Second Principle: i.i.d assumption: Training instances are drawn *independently* from the trainin set, and they are *identically distributed*\nWhy is this important? We can simplify the TS distribution:\nIndependent means that the joint distribution is the product of the individual distributions. Identically distributed means that all the instances come from the same prob-distribution, so I dont need a $p_i$ \n$$p(TS) = p(x_1, \\dots, x_n)= \\prod p(x_i)$$\n\nMaximum Likelihood: \n$$ \\hat \\mu, \\hat\\Sigma = \\arg \\max_{\\mu,\\Sigma} p(TS)$$\n\nMathematically simpler: minimize the negative Logarithm of p(TS)\n\n$$  \\arg \\max_{\\mu,\\Sigma} p(TS)\\leftrightarrow  \\arg \\min_{\\mu,\\Sigma} (-\\log p(TS))$$\n\nBecause if you apply a monotic function to an optimzation problem the arg max will not change. Taking a minus takes a maximum into a minimum\n\n$$ \\hat \\mu, \\hat\\Sigma = -\\arg \\min_{\\mu,\\Sigma} \\sum_i^N\\left( \\log \\left(\\frac{1}{\\sqrt{\\det(2\\pi\\Sigma)}} \\right)- \\frac{1}{2}(x_{i}- \\mu)\\Sigma^{-1}(x_{i}- \\mu)^{T}\n\\right)$$\n\n$$ \\hat \\mu, \\hat\\Sigma = \\arg \\min_{\\mu,\\Sigma} \\sum_i^N\\left( \\frac{1}{2} \\log  \\left(\\sqrt{\\det(2\\pi\\Sigma)} \\right)+ \\frac{1}{2}(x_{i}- \\mu)\\Sigma^{-1}(x_{i}- \\mu)^{T}\n\\right)$$\nWe can get rid of the scale facter 1/2 since it just scales and has no influence on the arg min. This is now our LOSS(TS) \n\nGeneral rule:\n\n$$\\log \\det(2 \\pi \\Sigma) = \\log ((2\\pi)^{D}\\det(\\Sigma)) = \\log(2\\pi)^{D}+ \\log \\det \\Sigma$$\n\n\nDerivative Rule from Linear Algebra:\n\n$$\\frac{\\partial vAv^{T}}{\\partial v}= 2Av^T$$\n$$\\frac{\\partial LOSS(TS)}{\\partial \\mu} = \\sum_{i} \\Sigma^{-1}(x_{i}-\\mu)^T=0 $$\nMultiply with $\\Sigma$ from the left:\n$$\\sum\\limits_{i}(x_{i}-\\mu)^T=0$$\n$$\\sum\\limits_{i}x_{i}=\\sum\\limits_{i}\\mu^{T}= N \\mu^T$$\n$$\\mu = \\frac{1}{N} \\sum\\limits_{i}x_{i}$$\nThe optimal $\\mu$ is the average. This is a mathematical proof that the average maximizes the likelihood of the data.\n\n$$\\frac{\\partial LOSS(TS)}{\\partial \\Sigma}$$ is inconvient.\n\nThe first term is rather easy\n\n$$\\frac{\\partial \\log\\det\\Sigma}{\\partial \\Sigma} = -(\\Sigma^{T)^{-1}}= -\\Sigma^{-1} $$\nsince $\\Sigma$ is symmetric.\n\nIntroduce precision matrix \n$$K = \\Sigma^{-1}$$\nCalculate:\n$$\\frac{\\partial}{\\partial K}  \\sum\\limits_i^{N}(x_i-\\mu)K(x_{i}-\\mu)^{T} = \\sum (x_{i}-\\mu)^{T} (x_{i}-\\mu)$$\nWhere the last term is called the scalar matrix.\n\nPut everything together:\n(kein bock mehr zu schreiben) Lecuture session 5,2023-05-02 Minute 1:01:11\n\n\n\n\n\n# Why is LDA a linear classifier?\nPriors:\n\n$$\np(y=1)=\\frac{N_1}{N} \\quad p(y=-1)=\\frac{N_{-1}}{N}\n$$\nassume for simplicity that these two are the same .i.e 1/2\n\nThe Gaussian for class 1 is given by\n$$\np(x | y=1)=\\frac{1}{\\sqrt{\\operatorname{det}(2 \\pi \\Sigma)}} \\exp \\left(-\\frac{1}{2}\\left(x- \\mu_1\\right) \\Sigma^{-1}(x-\\mu_1)^{\\top}\\right)\n$$\nThe decision rule is then given by the argmax of the posterior probability\n\n$$\n\\hat{y}_i=\\operatorname{argmax}_k p\\left(Y=k \\mid x_i\\right)\n$$\ninserting bayes rule gives\n\n$$\n\\hat{y}_i=\\operatorname{argmax}_{k}\\frac{p\\left(x_i \\mid y=k\\right) p\\left(y=k\\right)}{\\sum_{k^{\\prime}} p\\left(x_i \\mid y=k^{\\prime}\\right) p\\left(y=k^{\\prime}\\right)}=\\begin{cases}1 \u0026 \\text { if } p\\left(y=1 \\mid x_i\\right)\u003e\\frac{1}{2} \\\\ -1 \u0026 \\text { if } p\\left(y=1| x_i\\right)\u003c\\frac{1}{2} \\\\ \u0026 \\Leftrightarrow p\\left(y =-1 \\mid x_i\\right)\u003e\\frac{1}{2}\\end{cases}\n$$\n\n\nCalculate posterior analytically:\n$$\np(y=1 \\mid x)=\\frac{p(x \\mid y=1) p(y=1)}{p(x \\mid y=1) p(y=1)+p(x \\mid y=-1) \\mid p(y=-1)}\n$$\n$$=\\frac{p(x \\mid y=1)}{p(x \\mid y=1)+p \\mid(x \\mid y=-1)}$$\n$$\\begin{equation}\n\\begin{aligned}\n\u0026 =\\frac{1}{1+\\frac{p(x \\mid y=-1)}{p(x \\mid y=1)}} \\\\\n\u0026 \\frac{p(x \\mid y=-1)}{p(x \\mid y=1)}=\\exp \\left(-x \\Sigma^{-1}\\left(\\mu_1^{\\top}-\\mu_{-1}^{\\top}\\right)-\\frac{1}{2}\\left(\\mu_{-1} \\Sigma^{-1} \\mu_{-1}^{\\top}-\\mu_1 \\Sigma^{-1} \\mu_1^T\\right)\\right)=\\exp (-(x \\beta+b))\n\\end{aligned}\n\\end{equation}$$\n\n\n\nSo we get:\n$$\np(y=1\\mid x)=\\frac{1}{1+\\operatorname{exp}(-(x \\beta+b))}\n$$\nwhich is called the (logistic) sigmoid function\n![[Unbenannt.png]]\n\n\nThis satisfies:\n$$\n\\sigma(-t)=1-\\sigma(t)\n$$\n$$\n\\frac{d}{dt}\\sigma(t)=\\sigma(t) \\cdot \\sigma(-t)\n$$\n\nSo the posterior is simply\n$$\np(y=1 \\mid x)=\\sigma(x \\beta+b)\n$$\n$$\np(y=-1 \\mid x)=\\sigma(-(x \\beta+b))\n$$\nwhere \n$$\n\\begin{aligned}\n\u0026 \\beta=\\Sigma^{-1}\\left(\\mu_1^{\\top}-\\mu_{-1}^{\\top}\\right) \\\\\n\u0026 \\left.b=\\frac{1}{2}\\left(\\mu_{-1}\\Sigma^{-1} \\mu_{-1}^{\\top}-\\mu_1 \\Sigma^{-1} \\mu_{1}^{\\top}\\right)\\right)\n\\end{aligned}\n$$\nSo the decision rule is\n$$\n\\hat{y}=\\underset{k}{\\operatorname{argmax}} p(y=k \\mid x)\n$$\n$$\n\\Leftrightarrow\\left\\{\\begin{array}{lll}\n1 \u0026 \\text { if } \u0026  \\sigma(x \\beta+b)\u003e\\frac{1}{2} \\\\\n-1 \u0026 \\text { if } \u0026 \\sigma(-(x \\beta+b))\u003e\\frac{1}{2}\n\\end{array}\\right.\n$$\n$$\n\\Leftrightarrow\\left\\{\\begin{array}{lll}\n1 \u0026 \\text { if } \u0026 x \\beta+b\u003e0 \\\\\n-1 \u0026 \\text { if } \u0026 x \\beta+b\u003c0\n\\end{array}\\right.\n$$\n$$\n\\hat{y}=\\operatorname{sign}(x\\beta+b)\n$$\n\nWhich is linear!!!\n\n","lastmodified":"2023-05-14T20:14:57.504600218Z","tags":[]},"/notes/machine-learning/Logisitic-Regression":{"title":"Logisitic Regression","content":"\nUse the same posterior as [[Linear Discriminant Analysis]], but train LHS of Bayes rule, which gives a different solution.\n\n\n- i.i.d assumption: all labels are drawn independently from same posterior\n\n\n$$\np((Y_{i}^{*})_{i=1}^{N} \\mid (X_{i})_{i=1}^{N})=\\prod_{i=0}^Np(Y_i^{*} \\mid X_i)\n$$\n- Maximum Likelihood Principle: choose Parameters such that posterior of TS is maximized\n$$\n\\hat{\\beta},\\hat{b} =\\text { argmax }_{\\beta, b} \\prod_{i=1}^{N} p\\left(Y_{i}^{*}\\mid X_{i}\\right)\n$$ $$=\\arg \\min-\\sum\\limits_{i}^{N}\\log p\\left(Y_{i}^{*}\\mid X_{i}\\right)= \\arg \\min \\sum\\limits_{i: Y_{i}^{*}=1} \\sigma(x\\beta+b)-\\sum\\limits_{i: Y_{i}^{*}=-1} \\sigma(-(x\\beta+b)) $$\n\n\nwhich gives\n\n$$\\hat\\beta,\\hat b=\\arg \\min_{\\beta,b}-\\sum\\limits_{i=1}^{N}\\sum\\limits_{k}1[Y_{i}^{*}=k] \\log \\sigma_k(x\\beta+b)$$\n\n\nWhat is the logarithm of the sigmoid?\n![[Softplus Function]]\n\n\nCommon convention in literature is to write the labels as\n$$\ny_i^* \\in\\{0,1\\}\n$$\nThen the Logistic Regression Objective is\n\n\n$$\n\\hat{\\beta}, \\hat{b}=\\arg \\min _{\\beta, s}-\\sum_{i=1}^N\\left[Y _ { i } ^ { * } \\log \\sigma\\left(x \\beta+b)+\\left(1-Y_i^*\\right) \\log \\sigma(-(x \\beta+b))]\\right.\\right.\n$$\nThis has no analytic solution, but it is a convex objective, which means that iterative algorithms have unique solutions\nSo we make a simplifaction that if the features are centered, we can set $b=0$\n\nThe derivatives are:\n$$\n\\frac{\\partial \\sigma(x \\beta)}{\\partial \\beta}=\\sigma^{\\prime}(X \\beta) \\cdot x=\\sigma(X \\beta) \\cdot \\sigma(- x \\beta) \\cdot x\n$$\n$$\n\\frac{\\partial \\log \\sigma(x \\beta)}{\\partial \\beta}=\\frac{1}{\\sigma(x \\beta)} \\sigma(x \\beta) \\sigma \\sigma(-x \\beta) \\cdot x = \\sigma(-x\\beta)x\n$$\n$$\n\\frac{\\partial \\log \\sigma(-x \\beta)}{\\partial \\beta}=\\frac{1}{\\sigma(-x \\beta)} \\sigma(x \\beta) \\sigma \\sigma(-x \\beta) \\cdot (-x) = -\\sigma(x\\beta)x\n$$\nFrom which we can derive the derivate of the entire Training set\n\n$$\n\\frac{\\partial \\text { loss }(T S)}{\\partial \\beta}=-\\sum_{n=1}^N\\left[Y_{i}^{*} \\sigma\\left(-x_i \\beta\\right) x_i-\\left(1-Y_i^*\\right) \\sigma\\left(x_i \\beta\\right)\\left(-x_i\\right)\\right]\n$$\n\n\nWhich gives after simplifying \n$$\n\\frac{\\partial\\operatorname{loss}(\\partial \\beta)}{\\sigma_i}=\\sum_{i=1}^N\\left(\\sigma\\left(x_i \\beta\\right)-Y_i^*\\right) x_i \\quad \\stackrel{!}{=} 0\n$$\nThis explains what is happening: the term in the sum is basically the error\n\n- case 1: $Y_{i}^{*}=1$ and classifier correct: $\\sigma(X_i\\beta)=1$ -\u003e Error is close to 0\n-  case 2: $Y_{i}^{*}=1$ and classifier wrong: $\\sigma(X_i\\beta)\\approx 0$ -\u003e Error is close to -1 -\u003e so because we do gradient decent, this means we move $\\sigma(X_{i}\\beta)\\rightarrow 1$\n-  case 3: $Y_{i}^{*}=0$ and classifier correct: $\\sigma(X_i\\beta)=0$ -\u003e error is clos to 0, no correction\n-  case 4: $Y_{i}^{*}=0$ and classifier wrong: $\\sigma(X_i\\beta)=1$ -\u003e Error close to 1 --\u003e Correction (gradient descent) towards $\\sigma(X_{i}\\beta)\\rightarrow 0$\n","lastmodified":"2023-05-14T20:14:57.504600218Z","tags":[]},"/notes/machine-learning/Machine-Learning-Essentials":{"title":"Machine Learning Essentials","content":"\nHere are my Lecture Notes of the Machine Learning Essentials Lecture by Ullrich KÃ¶the , SS 2023, Heidelberg.\n- 02.05.2023:\n\t- [[Cross Validation]]\n\t- [[Linear Discriminant Analysis]]\n\t- [[Alternatives for learnine beta and b]]\n- 09.05.23 Session 8\n\t- [[Summary Linear Classification]]\n\t- [[Multi Class Classification]]\n\t- [[Non Linear Classification]]\n\t- [[Neural Networks]]\n- 12.05: \n\t- [[Backpropagation]]\n\t- \n\n\n","lastmodified":"2023-05-14T20:14:57.504600218Z","tags":["ml"]},"/notes/machine-learning/Multi-Class-Classification":{"title":"Multi Class Classification","content":"\nTwo Possibilites:\n\n- reduce to a set of 2-class problems\n- or: use a more powerful model\n\n\n# One- against-rest classification\n\nFor each class $k=1,..,c$ define $\\beta_4 b_k \\Rightarrow$ score $s_k=X_i \\beta_k+b_k$\nThese are then trained by treating $y_{i}^{*}=k$ as \"Class +1\" and $y_{i}^{*}\\neq k$ as \"Class -1\" i.e the rest. So we train $c$ classifiers in total.\n\nThen we need to make them comparable by normalizatoin\n$\\hat{\\beta}_4=\\frac{\\beta_k}{\\left\\|\\beta_k\\right\\|}, \\hat{b}_k=\\frac{b_k}{\\left\\|\\beta_k\\right\\|}$\n\n- Classify according to the biggest score, or \"dont know\" if all scores are bad\n\nso the decision rule is\n\n$$\n\\hat{y}_i=\\left\\{\\begin{array}{l}\n\\text { \"unkmon\" if } s_k\u003c\\varepsilon \\forall k \\\\\n\\operatorname{argmax}_k s_k\n\\end{array}\\right.\n$$\n\n\n# all-pairs\ntrain a linear model for all $k,k'$ which is $c(c-1)/2$ models in total\nScores for all pairs\n$$\ns_{kk^{\\prime}}=x_i \\beta_{k k^{\\prime}}+b_{k k^{\\prime}} \\text { for all } k^{\\prime} \\neq k\n$$\nif $s_{kk^{\\prime}}\u003e0 \\rightarrow$ one vote for class k, if $s_{kk^{\\prime}}\u003c0 \\rightarrow$ one vote for class k'\n\nIn the end:\n$$\\hat y_{i}= \\text{label with most votes or \"unkown if all k received about equally many\"}$$\n\n\n\n\n# Define posterior as sofrmax funtion\n![[Softmax Function]]\n\nstandard for neural network classification\n\nNow: train all $\\beta_k,b_k$ jointly i.e together at some time\n\nWe use the Loss function \n\n![[cross-entropy loss]]","lastmodified":"2023-05-14T20:14:57.504600218Z","tags":[]},"/notes/machine-learning/Multi-variate-Gaussian":{"title":"Multi variate Gaussian","content":"\n$$N\\left(x \\mid \\mu, \\Sigma\\right)=\\frac{\\exp \\left(-\\frac{1}{2}(\\mathbf{x}-\\boldsymbol{\\mu})^{\\mathrm{T}} \\boldsymbol{\\Sigma}^{-1}(\\mathbf{x}-\\boldsymbol{\\mu})\\right)}{\\sqrt{\\det{2\\pi\\Sigma}}}$$","lastmodified":"2023-05-14T20:14:57.504600218Z","tags":[]},"/notes/machine-learning/Neural-Networks":{"title":"Neural Networks","content":"\nDefinition of a Neuron:\n\n- inputs $Z_{in}$ (row vector)\n- computation: Linear function followed by non-linearity $$Z_{out}=\\varphi(Z_{in}\\cdot\\beta+b)$$ which we call the activation of a Neuron. We call $Z'=Z_{in}\\cdot\\beta+b$ the pre-activation. Why do we need this Non-linearities? Because with out them the whole Neural Network reduces to one single Linear Transformation, since a concatenation of Linear Transformation is again simply a linear Transfromation\n- There are popular activation functions $\\varphi(Z')$\n\t- identity function: $\\varphi(Z')=Z'$ is linear. Used as output of regression networks\n\t- classic choice: \n\t\t- $\\varphi(Z')= \\sigma(Z')$ (sigmoid)\n\t\t- $\\varphi(Z')= \\tanh(Z')$ \n\t- modern:\n\t\t- $\\varphi(Z')= \\operatorname{ReLu}(Z')$  despite its non differentiable at 0 it performs better than the sigmoid function\n\t\t- $$\\varphi(Z')= \\operatorname{LeakyReLu}(Z')=\\left\\{\\begin{array}{l}\nZ^{\\prime}\\quad\\text{if} \\quad Z^{\\prime}\u003e0 \\\\\n\\alpha Z^{\\prime}\\quad\\text{if} \\quad Z^{\\prime}\u003c0,\\alpha\u003e0\n\\end{array}\\right.$$Where $\\alpha$ is another hyperparameter or is learned\n- exponential linear unit:$$\n\\varphi\\left(z^{\\prime}\\right)=E L U\\left(z^{\\prime}\\right)=\\left\\{\\begin{array}{l}\nz^{\\prime} \\quad\\text{if} \\quad z^{\\prime}\u003e0 \\\\\n\\alpha\\left(e^{z^{\\prime}-1}\\right) \\quad\\text{if} \\quad z^{\\prime}\u003c0,\n\\end{array}\\right.\n$$\n- swish function:$$\n\\text { Swish }\\left(z^{\\prime}\\right)=z^{\\prime} \\cdot \\sigma\\left(z^{\\prime}\\right)\n$$\n\n\n\n---\n\nA Neural Network is simple created by connecting many Neurons \n - in parallel: these neurons form a layer\n - in series: \"deep\", means that we have many layers\n\nBasic Network type: fully connected, each Neuron is connected with every neuron on the next layer\n\nIn around 2005, People discovered that GPUs could implement these Networks really efficiently, which enabled much bigger networks and improve results. Additionally, big data became available for the first time, and you need big data in order to train a big network.\n\n--- \n## Activations Functions\n\nThe activation functions $\\varphi_1,...,\\varphi_{L-1}$ (where $L$ is the number of layers not counting the input) are chosen by the designer (\"hyperparamter\"), and is usually ReLU or ELU or swish.\n\nThe last layer $\\varphi_L$ is determined by application:\n- regression ($Y\\in \\mathbb{R}$ ): identity\n- classification ($\\left.p(Y=k \\mid x\\right))$ where $Y$ is a vector: softmax\n\nPossible interpretation: \n- $Z_{L-1}=\\psi([1,X])$: non-linear transformation of features (learned!) to fulfill requirements of last layer algorithm. The $\\psi$ function is the entire network until the last layer. \n- $Z_L=\\varphi_L\\left(\\left[1, Z_{L-1}\\right] \\cdot \\beta_L\\right)$: classical algorithm, e.g least squares regression, logistic regression(for classification)\n\n\n# Important theorems\n\n1. **Neural Networks with at least 2 layers are universal approximators**: This means that if the Network is big enough i.e we have enough neurons in the hidden layer, we can approximate **any** function to **any** desired accuracy. But: This is a purely existential proof: It says that the network exists, but it doesnt say anything about how to find (train) it. (\"The solution exists but we have no idea how to compute it\")\n2. **Finding the optimal network is NP-hard (takes exponential time in network size)**: If you make your network bigger you have a lower chance to finding the optimal parameters, so you need approximation algorithms are needed.\n\nThe error people did up to 2005 was that since 2-layers are sufficient, only use 2-layer nets. But it was found that deeper networks are easier to train since the probability that you end up in a good local optimum is essentially 1\n\n\nTrainint of these Networks is done by [[Backpropagation]]\n\n\n","lastmodified":"2023-05-14T20:14:57.504600218Z","tags":[]},"/notes/machine-learning/Non-Linear-Classification":{"title":"Non Linear Classification","content":"\nUsed when Data is not Linear separable\n\n0. Bad Practise: Use LR and hope for the best. Exception: Very sparse data, when its hard to justify non-linear fit\n1. Measure more features, increase $D$ or measure $x_i$ more accuratly. higher dimensional spaces tend to be more linearaly separable, but might be overfitting. There is a Theory that claims that $N=D+1$ is always seperable\n\nif $D\u003eN$: use sparse learning methods: (Automatically select for important features and ignore the rest e.g LASSO regression)\n\n2. Use non-linear classifier: e.g QDA (quadratic discriminant Analysis) is like LDA but seperate covariance $\\Sigma_k$ for each $k$ , which gives a curved decision boundary.\n\tPredict by the RHS of Bayes Formule\n\n\t- kernel-SVM: non-linear generelization of SVM\n\t- Decision trees/forests: recursively subdivide the x-space\n\n3. non-linearly transform features $\\tilde X_i = \\phi(x_i)$ and choose the transformation such that data are linearly seperable in $\\tilde X_i$ space.  The problem is  that handcraftign the function $\\phi$ is difficult and time consuming. The Solution is to lean the function using multi layer neural networks. So if you have L layers, the layers L,... L-1 implement the function $\\phi$ and the last Layer L is a linear classifier (Usually LR)","lastmodified":"2023-05-14T20:14:57.504600218Z","tags":[]},"/notes/machine-learning/Normalizing-Flows":{"title":"Normalizing Flows","content":"\n\nVortrag:\n- Historical Context: what is the Problem and why is a normalizing flow good for solving it?\n- \n\n\n\n![[Variational Inference with Normalizing Flows Paper]]\n\n\n\n\n\n\n![[Youtube Tutorial Brubaker Normalizing Flows]]\n\n\n\n\n\n\n# Luca\nautoregresive flows\ncoupling layers:\nuniversal approximator\n\n\nAndere generative modelle die nicht mit flows arbeiten.\n\n\nScore based model - flow based model?\n\nFlows kÃ¶nnen nicht nur samples generieren sondern die lernen die distribution selbst\n\n\nWas heisst das wenn wir sagen dass daten einer distribution folgen.\n\n\n\nLimit von Normalizing flows? Trainingszeit? high dimensionallity\n\n\nDeterminante berechnen geht mit O(n3)\n\n\nLoss function von Normalizing Flows?\nWie trainiert man normalizing flows??\n\n\n\n","lastmodified":"2023-05-14T20:14:57.504600218Z","tags":[]},"/notes/machine-learning/Softmax-Function":{"title":"Softmax Function","content":"\n\n$$\np\\left(\\hat{Y}_i=k \\mid X_i\\right)=\\frac{\\exp \\left(s_k\\right)}{\\sum_{\\dot{k}^{\\prime}=1}^c \\exp \\left(s_{k^{\\prime}}\\right)}=\\operatorname{softmax}(s_i,..,s_c)\n$$\n","lastmodified":"2023-05-14T20:14:57.504600218Z","tags":[]},"/notes/machine-learning/Softplus-Function":{"title":"Softplus Function","content":"\n\n$$\n-\\log \\sigma(t)=-\\log \\frac{1}{1+\\exp (-t)}=\\log (1+\\exp (-t))\n$$\nIs like a smoothed Version of ReLu","lastmodified":"2023-05-14T20:14:57.504600218Z","tags":[]},"/notes/machine-learning/Variational-Inference-with-Normalizing-Flows-Paper":{"title":"Variational Inference with Normalizing Flows Paper","content":"\n\nhttps://arxiv.org/pdf/1505.05770v6.pdf\n\n\n# Fragen:\n-  What is variational Inference?\n- Why is posterior approximation in variational inference a disadvantage\n- inferential and variational methods difference\n- \n\n\n\n\n\n\n\n\n# Notes on Paper:\n- variational methods have huge succes and ongoing advances, but have a number of disadvantges. One main limitation is the choice of posterior approximation that is adressed in the paper\n- Variational Inferences requires that intractable posterior distributions be approximated by class of known Probability distributions, over which we search for the true posterior\n\t- class of approximations is limited: i.e mean field approximation, implies that no solution is ever able to resemble true posterior distribution\n- Why are we interested in richer more faithful posterior approximations\n\t- evidence that it results in better performance.\n- Proposals for rich posterior approximations:\n\t- \n","lastmodified":"2023-05-14T20:14:57.504600218Z","tags":[]},"/notes/machine-learning/Youtube-Tutorial-Brubaker-Normalizing-Flows":{"title":"Youtube Tutorial Brubaker Normalizing Flows","content":"\nhttps://www.youtube.com/watch?v=u3vVyFVU_lI\u0026ab_channel=MarcusBrubaker\n\n\n\n# What are Normalizing Flows?\n\n- Probabilistic Generative Model built on invertible transformaitons\n- They are Generally:\n\t- Efficient to sample from $p_X(x)$\n\t- Efficient to evaulate $p_X(x)$ almost exactly\n\t- highly (flexibly) expressive\n\t- useful latent representation\n\t- straightforward to train\n\n\n# What are NF now mathematically?\n\nbasically just an application of the change of variables formula\n$$p_{x(x)}= p_z(f(x))|det Df(x)|$$\nwhere\n- Z=f(X) is an invertible and differentiable $f(x)$ transformation\n- Volume correction term: $Df(x)$ is the Jacobian\n\n## Basic Idea of Normalizing Flows:\nAssume we have a given X which are e.g images. We want to choose an convenient, easy to work with distribution of Z, $p_Z(Z)$\nWhat normalizing flow does given this formula it tries to find the function $f(x)$ that transforms the very complex distribution over X into an nice simple distribution of Z. We want the distribution of images look like simple gaussian noise.\n\ni.e\n\nLearn $f(x)$ to transform data distribution $p_X(x)$ into $p_Z(z)$\n\ntwo main pieces:\n- Base Measure: $p_Z(z)$ is typically a standard normal distribution\n- Flow $f(x)$ must be invertible and differentiable\n\n\n\nTraining is mostly done via maximum log likelihood\n$$\\max_\\theta\\sum\\limits_{i}^{N} \\log p_{z}(f(x_{i}| \\theta ))+ \\log |\\det Df(x_{i}|\\theta)|$$\n","lastmodified":"2023-05-14T20:14:57.504600218Z","tags":[]},"/notes/machine-learning/cross-entropy-loss":{"title":"cross-entropy loss","content":"?\n\n\n\nSolve by gradient decent since it has no analytic solution\n","lastmodified":"2023-05-14T20:14:57.504600218Z","tags":[]},"/notes/physics/Navier-Stokes-Equations":{"title":"Navier-Stokes Equations","content":"\n$$\n\\frac{\\partial \\vec{v}}{\\partial t}+(\\vec{v} \\cdot \\vec{\\nabla}) \\vec{v}=-\\frac{1}{\\rho} \\vec{\\nabla} p-2(\\vec{\\Omega} \\times \\vec{v})+\\nu \\Delta \\vec{v}+\\vec{g}\n$$\n\n- $\\frac{\\partial \\vec{v}}{\\partial t}$: This term represents the partial derivative of the velocity vector (\\vec{v}) with respect to time (\\partial t). It captures the change in velocity over time and represents the acceleration or deceleration of the fluid particles.\n\n- $(\\vec{v} \\cdot \\vec{\\nabla}) \\vec{v}$: This term corresponds to the convective or advective term. It involves the dot product (\\cdot) between the velocity vector (\\vec{v}) and the gradient operator (\\vec{\\nabla}), followed by another dot product with the velocity vector (\\vec{v}). It describes the effect of the fluid's own velocity on the acceleration of neighboring fluid particles and represents the transport of momentum within the flow.\n\n- -$\\frac{1}{\\rho} \\vec{\\nabla} p:$ This term represents the pressure gradient in the fluid. It involves the gradient operator (\\vec{\\nabla}) acting on the scalar pressure field (p). Dividing by the density (\\rho) accounts for the influence of pressure on the acceleration of the fluid particles.\n\n- $2(\\vec{\\Omega} \\times \\vec{v})$: This term represents the Coriolis force. It involves the cross product (\\times) between the angular velocity vector (\\vec{\\Omega}) and the velocity vector (\\vec{v}). It captures the effect of the rotation of the coordinate system on the fluid flow.\n\n- $\\nu \\Delta \\vec{v}$: This term represents the viscous forces in the fluid. It involves the Laplacian operator (\\Delta) acting on the velocity vector (\\vec{v}), and multiplying by the kinematic viscosity (\\nu). It accounts for the internal friction within the fluid, causing velocity gradients and damping the flow.\n\n- $\\vec{g}$: This term represents the gravitational force acting on the fluid. It corresponds to the vector gravitational acceleration (\\vec{g}) and influences the fluid flow by causing it to move in the direction opposite to the gravitational field.\n\nOverall, this equation, known as the Navier-Stokes equation, describes the conservation of momentum in a fluid and captures the various forces and terms influencing the fluid flow.\n","lastmodified":"2023-05-14T20:14:57.504600218Z","tags":[]},"/tags/setup":{"title":"setup","content":"","lastmodified":"2023-05-14T20:14:57.504600218Z","tags":[]}}